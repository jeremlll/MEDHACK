{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MEDHACK LSTM Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded! Shape: (12055680, 16)\n",
      "             timestamp                            patient_id first_name  \\\n",
      "0  2025-01-01 19:00:00  b317e7ee-8af7-3e9c-3e0f-646395b8c81a  Howard613   \n",
      "1  2025-01-01 19:00:05  b317e7ee-8af7-3e9c-3e0f-646395b8c81a  Howard613   \n",
      "2  2025-01-01 19:00:10  b317e7ee-8af7-3e9c-3e0f-646395b8c81a  Howard613   \n",
      "3  2025-01-01 19:00:15  b317e7ee-8af7-3e9c-3e0f-646395b8c81a  Howard613   \n",
      "4  2025-01-01 19:00:20  b317e7ee-8af7-3e9c-3e0f-646395b8c81a  Howard613   \n",
      "\n",
      "       last_name  age gender           address       city state  postcode  \\\n",
      "0  Altenwerth646   42      M  2/58 JASPER ROAD  BENTLEIGH   VIC      3204   \n",
      "1  Altenwerth646   42      M  2/58 JASPER ROAD  BENTLEIGH   VIC      3204   \n",
      "2  Altenwerth646   42      M  2/58 JASPER ROAD  BENTLEIGH   VIC      3204   \n",
      "3  Altenwerth646   42      M  2/58 JASPER ROAD  BENTLEIGH   VIC      3204   \n",
      "4  Altenwerth646   42      M  2/58 JASPER ROAD  BENTLEIGH   VIC      3204   \n",
      "\n",
      "   diastolic_bp  systolic_bp  heart_rate  respiratory_rate  oxygen_saturation  \\\n",
      "0          79.9        118.3        74.4              17.1               98.6   \n",
      "1          79.2        119.0        75.8              16.0               96.0   \n",
      "2          80.8        119.6        74.3              16.5               96.8   \n",
      "3          81.3        120.2        75.1              16.9               96.9   \n",
      "4          79.9        118.2        75.9              16.3               97.2   \n",
      "\n",
      "   state_label  \n",
      "0            0  \n",
      "1            0  \n",
      "2            0  \n",
      "3            0  \n",
      "4            0  \n",
      "Test Data Loaded! Shape: (325440, 16)\n",
      "   ID            timestamp                            patient_id first_name  \\\n",
      "0   1  2025-01-01 19:00:00  d8cdccaa-9bc6-4b08-ee28-7dfaa0f07caf  Sammie902   \n",
      "1   2  2025-01-01 19:00:05  d8cdccaa-9bc6-4b08-ee28-7dfaa0f07caf  Sammie902   \n",
      "2   3  2025-01-01 19:00:10  d8cdccaa-9bc6-4b08-ee28-7dfaa0f07caf  Sammie902   \n",
      "3   4  2025-01-01 19:00:15  d8cdccaa-9bc6-4b08-ee28-7dfaa0f07caf  Sammie902   \n",
      "4   5  2025-01-01 19:00:20  d8cdccaa-9bc6-4b08-ee28-7dfaa0f07caf  Sammie902   \n",
      "\n",
      "   last_name  age gender            address      city state  postcode  \\\n",
      "0  Brakus656   11      M  31 CHELSEA STREET  BRIGHTON   VIC      3186   \n",
      "1  Brakus656   11      M  31 CHELSEA STREET  BRIGHTON   VIC      3186   \n",
      "2  Brakus656   11      M  31 CHELSEA STREET  BRIGHTON   VIC      3186   \n",
      "3  Brakus656   11      M  31 CHELSEA STREET  BRIGHTON   VIC      3186   \n",
      "4  Brakus656   11      M  31 CHELSEA STREET  BRIGHTON   VIC      3186   \n",
      "\n",
      "   diastolic_bp  systolic_bp  heart_rate  respiratory_rate  oxygen_saturation  \n",
      "0          87.0        145.5       112.4              16.8               98.4  \n",
      "1          86.3        145.7       112.6              15.0               96.5  \n",
      "2          86.0        146.5       110.9              16.0               97.3  \n",
      "3          87.0        147.0       111.4              15.2               97.7  \n",
      "4          85.9        145.2       112.1              15.0               97.6  \n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "dataset_df = pd.read_csv('train_data.csv')\n",
    "print(\"Data Loaded! Shape:\", dataset_df.shape)\n",
    "print(dataset_df.head())\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv('test_data.csv')\n",
    "print(\"Test Data Loaded! Shape:\", test_df.shape)\n",
    "print(test_df.head())\n",
    "\n",
    "\n",
    "# 2.1: Drop columns we don't want or need from training data\n",
    "# They might not directly help us predict in a simple DNN approach.\n",
    "dataset_df = dataset_df.drop([\n",
    "    'first_name', 'last_name',\n",
    "    'address', 'city', 'state', 'postcode'\n",
    "], axis=1)\n",
    "\n",
    "test_df = test_df.drop([\n",
    "    'first_name', 'last_name',\n",
    "    'address', 'city', 'state', 'postcode'\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in training data:\n",
      " timestamp            0\n",
      "patient_id           0\n",
      "age                  0\n",
      "gender               0\n",
      "diastolic_bp         0\n",
      "systolic_bp          0\n",
      "heart_rate           0\n",
      "respiratory_rate     0\n",
      "oxygen_saturation    0\n",
      "state_label          0\n",
      "dtype: int64\n",
      "Training Features shape: (9041760, 9)\n",
      "Training Labels shape: (9041760,)\n",
      "Training Features shape: (3013920, 9)\n",
      "Training Labels shape: (3013920,)\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# 2. Preprocessing\n",
    "# =========================================================\n",
    "\n",
    "\n",
    "# 2.1: Check for missing values\n",
    "print(\"Missing values in training data:\\n\", dataset_df.isna().sum())\n",
    "# print(\"Missing values in test data:\\n\", test_df.isna().sum())\n",
    "\n",
    "# Example strategy: just drop rows with missing data.\n",
    "# (Real-world might do more nuanced imputation.)\n",
    "dataset_df = dataset_df.dropna()\n",
    "# test_df = test_df.dropna()\n",
    "\n",
    "# 2.2: Extract features (X) and labels (y) from the training set\n",
    "X_all = dataset_df.drop('state_label', axis=1)\n",
    "y_all = dataset_df['state_label']\n",
    "\n",
    "# Perform the split (default is 75% train, 25% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all, \n",
    "    y_all,\n",
    "    test_size=0.25,     # Size of the test set (0.25 = 25% of data)\n",
    "    random_state=42,     # Set seed for reproducibility\n",
    "    shuffle=True         # Shuffle the data before splitting\n",
    ")\n",
    "\n",
    "#2.4 Extract features (X) and labels (y) from the training set\n",
    "print(\"Training Features shape:\", X_train.shape)\n",
    "print(\"Training Labels shape:\", y_train.shape)\n",
    "\n",
    "\n",
    "#2.4 Extract features (X) and labels (y) from the testing set\n",
    "print(\"Training Features shape:\", X_test.shape)\n",
    "print(\"Training Labels shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "def prepare_sequences(df, sequence_length=12, step=1):\n",
    "    \"\"\"\n",
    "    Prepare sequences for LSTM model from DataFrame.\n",
    "    sequence_length: number of time steps in each sequence (12 = 1 hour with 5-min intervals)\n",
    "    step: number of time steps to move forward for next sequence\n",
    "    \"\"\"\n",
    "    features = ['diastolic_bp', 'systolic_bp', 'heart_rate', \n",
    "                'respiratory_rate', 'oxygen_saturation', 'age']\n",
    "    \n",
    "    # Create sequences for each patient\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    \n",
    "    for patient_id in df['patient_id'].unique():\n",
    "        patient_data = df[df['patient_id'] == patient_id].sort_values('timestamp')\n",
    "        \n",
    "        # Convert gender to numeric\n",
    "        gender_numeric = (patient_data['gender'] == 'M').astype(int).iloc[0]\n",
    "        \n",
    "        # Get patient features\n",
    "        patient_sequence = patient_data[features].values\n",
    "        patient_states = patient_data['state_label'].values\n",
    "        \n",
    "        # Add gender as a constant feature\n",
    "        patient_sequence = np.column_stack([patient_sequence, \n",
    "                                          np.full(len(patient_sequence), gender_numeric)])\n",
    "        \n",
    "        # Create sequences\n",
    "        for i in range(0, len(patient_sequence) - sequence_length + 1, step):\n",
    "            sequences.append(patient_sequence[i:i + sequence_length])\n",
    "            labels.append(patient_states[i + sequence_length - 1])\n",
    "    \n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "# Prepare the data\n",
    "sequence_length = 12  # 1 hour of data\n",
    "X_sequences, y_sequences = prepare_sequences(dataset_df, sequence_length)\n",
    "\n",
    "# Split into train and validation sets\n",
    "train_idx = int(0.8 * len(X_sequences))\n",
    "X_train, X_val = X_sequences[:train_idx], X_sequences[train_idx:]\n",
    "y_train, y_val = y_sequences[:train_idx], y_sequences[train_idx:]\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_reshaped = X_train.reshape(-1, X_train.shape[-1])\n",
    "X_val_reshaped = X_val.reshape(-1, X_val.shape[-1])\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train_reshaped)\n",
    "X_val_scaled = scaler.transform(X_val_reshaped)\n",
    "\n",
    "X_train_scaled = X_train_scaled.reshape(X_train.shape)\n",
    "X_val_scaled = X_val_scaled.reshape(X_val.shape)\n",
    "\n",
    "# Convert labels to categorical\n",
    "y_train_cat = to_categorical(y_train)\n",
    "y_val_cat = to_categorical(y_val)\n",
    "\n",
    "# Create and compile the model\n",
    "def create_model(sequence_length, n_features):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(64, input_shape=(sequence_length, n_features), \n",
    "                            return_sequences=True),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.LSTM(32),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(16, activation='relu'),\n",
    "        tf.keras.layers.Dense(4, activation='softmax')  # 4 classes (0,1,2,3)\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create and train the model\n",
    "model = create_model(sequence_length, X_train.shape[-1])\n",
    "\n",
    "# Class weights to handle imbalance\n",
    "class_weights = dict(enumerate(\n",
    "    1 / np.bincount(y_train) * len(y_train) / 4\n",
    "))\n",
    "\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train_cat,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val_scaled, y_val_cat),\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=3,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting functions\n",
    "def plot_training_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    ax1.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot loss\n",
    "    ax2.plot(history.history['loss'], label='Training Loss')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "\n",
    "# Generate and plot model diagnostics\n",
    "plot_training_history(history)\n",
    "\n",
    "# Generate predictions\n",
    "y_pred = model.predict(X_val_scaled)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_val_classes = np.argmax(y_val_cat, axis=1)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(y_val_classes, y_pred_classes)\n",
    "\n",
    "# Print classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val_classes, y_pred_classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
